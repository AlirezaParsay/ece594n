{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8ea5f2",
   "metadata": {},
   "source": [
    "<h1><center>Homework 2: Reproducibility</center></h1>\n",
    "\n",
    "\n",
    "<h3><center>by Abhijith Atreya & Jax Burd</center></h3>\n",
    "\n",
    "<center>UCSB ECE 194N/594N</center>\n",
    "\n",
    "<center>Nina Miolane</center>\n",
    "\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Jax started the homework a bit earlier and ended up running into a number of headaches to be reported below. Because of this, our group's approach was to try and reproduce the figures from the given paper separately and give eachother help where possible. Turns out even though both of us are ECE grad students, we could only get through so much of the provided code and source data.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Jax's Analysis\n",
    "\n",
    "## Useful Background\n",
    "- MS ECE student\n",
    "- Vaguely familiar with Machine Learning\n",
    "- Highschool level understanding of biology\n",
    "- Research papers and I are **not** friends\n",
    "\n",
    "## Initial Approach\n",
    "1. Read the paper (at least the first 16 pages)\n",
    "2. Understand Figure 1\n",
    "3. Download the source data\n",
    "4. Use given code to recreate figures\n",
    "\n",
    "## Actual Process\n",
    "\n",
    "### 1. Reading the Paper\n",
    "This was probably the hardest part for me. Sitting down and actively reading the paper for complete understanding was exhaustive and ended up taking up way too much time. I'm already a slow reader, but it doesn't help when every other word clearly from a biology background pops up and I have to look it up. To be honest, I'm not sure how much of when I looked up then I retained and can recite to you know.\n",
    "\n",
    "Other than the terminology being hard to get through, I actually found the **figures themselves** hard to understand. Again it would help if I had the necessary background konwledge, but as a newbie looking at the figures for the first time I thought there was *alot* going on. Firstly, I went back and forth many times to piece together parts of the figures to what they're suppose to be representing. There's only 7 figures total in the paper, each taking about from half of to an entire page, but all of them are comprised of many other **sub-figures**. If you showd me those figures without the rest of the paper I'd be completely lost.\n",
    "\n",
    "It wasn't until **page 4** of the paper that I saw the hyperlink saying \"see data and code availability\" that I felt a bit better about this homework. In total I spent over 3 hours spread across a couple evenings to get through reading the entire paper, still only coming away with a baseline understanding of the authors attempted methods and results.\n",
    "\n",
    "- **Task Time: 3+ hours**\n",
    "\n",
    "### 2. Data and Code Availability\n",
    "Next was going through each of the provided links in the paper under the **Resource Availability** section. I looked through the main three resources 1) Source Data 2) Code and 3) Scripts. They were so nicely linked I thought going through the code was going to be a bit more reasonable than going through the paper, but I was slightly off with that assumption. I made notes on my difficulties with each of the links below.\n",
    "\n",
    "### 1. Source Code\n",
    "\n",
    "- **Link:** https://open.quiltdata.com/b/allencell/packages/aics/integrated_transcriptomics_structural_organization_hipsc_cm\n",
    "\n",
    "I wasn't familiar with quilt data before this, and the Readme had a good skeleton structure of what data was featured. The lines \"Not all of these data were used in the manuscript, but all of the data used in the manuscript are included here\" and \"The data are programmatically accessible via quilt, and is also (somewhat) browse-able via this web ui\" made me chuckle because indeed the UI was a little awkward to navigate.\n",
    "\n",
    "To be honest the provided **schematic** showing the data creation and processing pipeline was difficult for me to follow. Most likely because I'm not an expert in this by any means, but also it felt just like a lot was packed into the diagram of what you can tell was a complicated process. And when I did start browsing through the data that I was going to be putting on my laptop, I wasn't familiar with tiff files, but appreciated the explanations of what was in each folder and how to interact with the data.   \n",
    "\n",
    "The **Bulk Download** section said you could pip install quilt, but since quilt3 was an available package you could automatically install through anaconda I tried that first. Initally it was giving me an error that quilt required an older version of python.\n",
    "- **UnsatisfiableError: The following specifications were found\n",
    "to be incompatible with the existing python installation in your environment**\n",
    "\n",
    "So I reverted back to using pip install which had no problems and was compatible with my newer version of python. I recognized the next part of the code to be python so I immediately tried running it in a script but kept seeing an error that didn't recognize \"quilt3\". Knowing that quilt wasn't available to download on Anaconda but quilt3 was, I pip installed quilt3 on a whim and that actually to care of my original error. The only problem was now the python file I was running showed a loading bar that stayed at 0% for over an hour. I actually ended up stopping my program out of frustration but when I looked back in the folder it seemed like everything had downloaded. Not sure when, but the program never did terminate on its own. In total I spent about an 2 hours looking through the data folders and trying to download them directly from quilt.\n",
    "\n",
    "- **Task Time:** 2 hours\n",
    "\n",
    "\n",
    "### ii. Code\n",
    "**Link:** https://github.com/AllenCellModeling/fish_morphology_code\n",
    "\n",
    "Actually looking at this github repo of the code was a better experience that with quilt since I'm already familiar with github and cloning the repository was easy. It was sort of annoying how I had to have a separate environment running python 3.7 in order to install everything, but I suppose it was no extra work on my part. I tried out running the code just to see if I could run something right away but I was confused at first where to run from since the instructions say to \" run the image normalization code, **from the main repo dir**\" which took me a while to figure out theres a **fish_morphology_code folder** *inside* of the main **fish_morphology_code folder**. Still I wasn't getting any luck running the following line anywhere in my directories, so I backtracked and followed the **Developer's Installation Instructions** which took quilt sometime to install and uninstall things from my environment. \n",
    "\n",
    "`contrast_and_segment quilt_data/metadata.csv quilt_data/supporting_files/channel_defs.json --out_dir=output_data`\n",
    "\n",
    "I was no longer seeing an error searching for \"contrast_and_segment\" but I was getting the following error\n",
    "- **FileNotFoundError: [Errno 2] No such file or directory: 'quilt_data/supporting_files/channel_defs.json'**\n",
    "\n",
    "So after searching the repo again the only mentions of \"quilt_data\" were in the README.md file, /.gitignore, and a third python file. It took me a while to understand that quilt_data was a placeholder for the folder from the quilt data you wanted to *run the code on*. I wasn't quite sure what I data I should be \"auto-contrasting\" in the first place, but since pretty much every folder in the data I downloaded earlier had a \"metadata.csv\" and \"supporting_files\" folder. I tried about half of them. I ran into a number of *Key Errors* and others that in general said I was missing something or the file parsed through was incompataible. I grew tired of trying to run the actual code after getting nowhere and moved on to the next link given in the original paper. In total I spent about 4 hours to setup the repo with all necessary packages download understand the how to run the repo with the quilt data and trying to understand how to get the code featured on the README page of the repo to work with the data I installed with quilt.\n",
    "\n",
    "- **Task Time:** 4 hours\n",
    "\n",
    "\n",
    "**Link:** https://github.com/AllenCellModeling/napari-annotation-tools\n",
    "\n",
    "\n",
    "### iii. Scripts\n",
    "**Link:** https://github.com/AllenCellModeling/fish_morphology_manuscript_notebooks/\n",
    "\n",
    "\n",
    "Where I did end up seeing some sucess was setting up the manuscript notebook that generated figures. I cloned the repo into a separate folder and it wasn't until I looked in the *requirements.txt* file that I realized this jupyter notebook for generating figures needed to be in the fish_morphology_code folder. This was confirmed by seeing **from fish_morphology_code.analysis.notebook_utils** in the notebook's list of imports. After installing *pingouin as pg* into my anaconda environment, and seemingly everything was in the correct place. I got another error saying I couldn't run the final import of *fish_morphology_code.analysis.notebook_utils* as the analysis subfolder was missing. Sure enough my main fish_morphology_code folder had no analysis subfolder, even on the repo. I was (embarassingly) stumped for 45 minutes until I remembered the **fish_morphology_code subfolder** and finally was able to run all the initial import code of \"manuscript_figs_public\" without any errors. \n",
    "\n",
    "I carefully started running each of the plots in the jupyter notebook, and for the most part things seemed to work nicely.\n",
    "Although things ran, I got plenty of **warnings** about the code using \"out dated methods\" of the various packages installed. Here were some of the main ones that popped up over and over again:\n",
    "\n",
    "- **FutureWarning:** `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
    "  warnings.warn(msg, FutureWarning)\n",
    "  \n",
    "  \n",
    "- **FutureWarning:** The `bw` parameter is deprecated in favor of `bw_method` and `bw_adjust`. Using 0.1 for `bw_method`, but please see the docs for the new parameters and update your code.\n",
    "  warnings.warn(msg, FutureWarning)\n",
    "  \n",
    "  \n",
    "- **UserWarning:** Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations.\n",
    "\n",
    "\n",
    "- **UserWarning:** 11.4% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
    "  warnings.warn(msg, UserWarning)\n",
    "  \n",
    "  \n",
    "- **FutureWarning:** The `frame.append` method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
    "\n",
    "The only figure that I ended up having to skip generating was under the section **5b spearman correlation bar charts** because it was taking way too long. After about waiting for 30 minutes I just interrupted the kernel and moved on with generating the next plots cause I was too impatient. I eventually went back because the warnings annoyed me so much when scrolling through, I ended up spending an extra hour going through and fixing all the warnings to their suggest fixes so the notebook wouldn't have red warnings every other line. \n",
    "\n",
    "- **Task Time:** < 3 hours\n",
    "\n",
    "### 3. Comparing the Figures\n",
    "\n",
    "What took a suprising amount of time (and where I'd end my efforts) was matching each of the figures I generated to the ones on the inital paper. They didn't look as nice, but more surprisingly many of the figures generated just weren't to be found. I assumed something with the title \"2C\" in the manuscripts notebook to correspect to Figure 2 subsection C on the original paper, but there was no correspondance at all. Most of the generated plots I think were useful to the study but never made it to the final draft of the paper. I spent probably 30 minutes going through all the figures I generated and (trying to) match them with anything within the research paper's 7 diagrams. The groups of plots below show a few of the diagrams I was able to match up, the top row being what I was able to generate and the bottom row being what was in the paper.\n",
    "\n",
    "![](images/Notebook_Main_Plot.JPG)\n",
    "\n",
    "- **Task Time:** 30 minutes\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "I think this paper was interesting but a combination of my little background in ML and pretty much none in transcriptomics and cellular organization I was *very* lost. Being able to generate the figures that I did was cool, but I don't think I could fully explain to you what each of them represents. I blame mostly myself for fumbling alot with the code's setup process, but it would have been alot easier if the data, code, and scripts weren't all in different places, each with their own sets of instructions. Probably the fastest way to start using this data would have to be through help from someone who's familar with the dataset and study itself, otherwise it's sort of a pain to navigate through the large number of files the project provides on your own. Telling by the little figures I was able to make and the many hours of struggle I went through I'd give working on this homework a **difficulty rating of 8/10**, 1 being super easy and 10 being the most difficult thing I've every experienced. \n",
    "\n",
    "### Total Time: 12+ Hours\n",
    "\n",
    "\n",
    "# Abhijith's Analysis\n",
    "\n",
    "## 1. Theory\n",
    "\n",
    "  - Due to limited background in biology, it took a large amount of time to read the paper. \n",
    "  - After spending about 3 hours on the paper, it still feels like lot of thigs are beyond comprehension.\n",
    "\n",
    "\n",
    "\n",
    "## 2. Code setup\n",
    "\n",
    "  - Repository consists of multiple folders and readme can do a better job in explaining the folder structure.\n",
    "  - Attmepted to download the entire dataset. But the size of the dataset is too large (~4TB)\n",
    "  - Resorted to download only a paritcular segment of the data-set\n",
    "  - The CLI specified in the website did not work, so had to use the python code specified in the website.\n",
    "  - **Task time :** 2 hrs\n",
    "\n",
    "    \n",
    "## 3. Running the code:\n",
    "\n",
    "  - Tried to run the the auto-contrasting code on `2d_nonstructure_fields` dataset using the following command :\n",
    "  `contrast_and_segment 2d_nonstructure_fields/metadata.csv 2d_nonstructure_fields/supporting_files/channel_defs.json --out_dir=output_data`.\n",
    "  \n",
    "      But the following error occurs:\n",
    "  \n",
    "    `\n",
    "    File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
    "    File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
    "    KeyError: '2D_fov_tiff_path'`\n",
    "\n",
    "  - Tried running cellprofiler to calculate single cell shape and texture features, but the follwoing error was observed:\n",
    "\n",
    "    ` File \"/home/abhi/ucsb/GeometricML/hw2/fish_morphology_code/fish_morphology_code/bin/                  make_cellprofiler_image_set.py\", line 47, in make_imageset\n",
    "      raise ValueError(\n",
    "      ValueError: Undefined fish_type; allowed values are 'structure' and 'nonstructure' `\n",
    "    - Tried the same procedure on multiple data-sets but, the same error occurs.\n",
    "  - 'make build' also failed with the following error:\n",
    "  \n",
    "    `ERROR:   py37: commands failed\n",
    "      ERROR:   lint: commands failed\n",
    "      make: *** [Makefile:50: build] Error 1`\n",
    "\n",
    "    - Tried cleaning the repository and building it again, however the same error occurs.\n",
    "    \n",
    "    - Verified conda environment and installed package versions, with the proposed ones to be the same, but    the error could not be fixed\n",
    "\n",
    "  - Also, tried to train the model using the procedure specified in `/fish_morphology_code/fish_morphology_code/processing/structure_organization/README.md`\n",
    "\n",
    "    - However, after setting up the environment, when I run 'model_training.py', I get the following error: \n",
    "\n",
    "    ` raise S3NoValidClientError(f\"S3 AccessDenied for {api_type} on bucket: {bucket}\")\n",
    "      quilt3.data_transfer.S3NoValidClientError: S3 AccessDenied for S3Api.GET_OBJECT on bucket: allencell-internal-quilt`\n",
    "\n",
    "    -Running code as super user did not help.\n",
    "\n",
    "  - **Task time :** 5 hrs\n",
    "    \n",
    "## 4. Running the notebook:\n",
    "\n",
    "  - By following the code present in `AllenCellModeling/fish_morphology_manuscript_notebooks`, I was able to generate some figures.\n",
    "  - Problems with the notebook: There are some deprecated funcitons being used, which are producing warnings.\n",
    "    Eg : `FutureWarning: distplot is a deprecated function and will be removed in a future version`\n",
    "\n",
    "          `DeprecationWarning: np.complex is a deprecated alias for the builtin complex. To silence this warning, use complex by itself.`\n",
    "  - I was able to correlate the figures generated in the manuscript notebook to the figures in the paper.\n",
    "\n",
    "  - **Task time :** 30 mins\n",
    "\n",
    "## Conclusion \n",
    "\n",
    "  - Overall, I would say that users will require some background knowledge in the field of biology and programming to set-up this code and interpret the results. Due to my lack of understanding in the field of biology, I found it tough to interpret the graphs and plits which were generated by the mauscript-notbook.\n",
    "\n",
    "  - I feel that the information found in the discussion forum ( `https://forum.allencell.org/`) is helpful, but video tutorials on running the `fish_morphology_code` would be better.\n",
    " \n",
    "    \n",
    "\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f91c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
