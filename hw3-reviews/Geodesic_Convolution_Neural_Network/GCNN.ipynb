{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e98936-d21d-4216-988b-6af826c6199f",
   "metadata": {},
   "source": [
    "# Geodesic convolutional neural networks on Riemannian manifolds\n",
    "by Jonathan Masci†∗ Davide Boscaini†∗ Michael M. Bronstein† Pierre Vandergheynst, USI, Lugano, Switzerland, EPFL, Lausanne, Switzerland\n",
    "<a href=\"https://arxiv.org/abs/1501.06297\">DOI: arXiv:1501.06297</a>\n",
    "\n",
    "Author: Ian Wu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd760d-da5a-4d7d-ac77-06202e4634a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Abstract\n",
    "\n",
    "Geodesic convolutional neural netowrk (GCNN) is a new generalization of the convolutional networks (CNN) paradigm to non-Euclidean manifolds. It achieves state of the art performance for solving shape description, retrieval, and correspondance problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da748a-0679-4103-a947-026bc61b7d76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I. Introduction\n",
    "Shapes descriptors are essential for shape anlaysis. There are mainly two types of feature descriptors:\n",
    "\n",
    "### Local feature descriptor\n",
    "It is assigned to each point on the shape representing the local structure.\n",
    "It is used in higher-level tasks such as establishing correspondence between shapes, shape retrieval, or segmentation.\n",
    "\n",
    "### Global feature descripter\n",
    "It is producde by aggregating local descriptors to describe the whole shape (ex: bag of features in NLP)\n",
    "\n",
    "\n",
    "#### Intrinsic VS Extrinsic:\n",
    "<figure>\n",
    "<img src = 'img/Intrinsic_vs_Extrinsic.png' style=\"width:50%\">\n",
    "<figcaption align = \"right\"><b>Fig. 1 Intrinsic vs Extrinsic </b></figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Previous Works focus on using **extrinsic structures** that are invariant under Euclidean transformation.\n",
    "#### Examples:\n",
    "[1] Spine Image Descriptors: It is a surface representation technique. It encodes global properties of any surface in an object-oriented coordinate system rather than in a viewer-oriented coordinate system.<br>\n",
    "[2] Tntegral Volume Descriptor: It uses density as the integrand and mass as the integral. These features are used to compare objects represented as closed planar contours.\n",
    "\n",
    "\n",
    "Newer works focus on **intrinsic structure** (geodesic distance) that are invariant under isometric deformations. <br>\n",
    "#### Examples:\n",
    "[3] SIFT: It uses keypoints to locate local features. These keypoints are scale & rotation invariant that can be used for image matching, object detection and scene detection.\n",
    "[4] Heat Kernel Signature: HKS based  is based on the concept of heat diffusion over a surface. Given an initial heat distribution over the surface, the heat kernel h_{t}(x,y) relates the amount of heat transferred from x to y under after time t. The heat kernel is invariant under isometric transformations and stable under small perturbations to the isometry.<br>\n",
    "[5] Wave Kernel Signatures: Similar to HKS, WKS uses Schrödinger wave equation instead of heat equation to compue the similarity between shapes.<br>\n",
    "\n",
    "### Deep Learning Methods\n",
    "Learning methods are becoming more and more popular in the field of 3D shape analysis. It is used extensively in in problems such as shape correspondence, similarity description, and retrieval. Intrinsic versions of CNNs that would allows dealing with shape deformations are difficult to formulate due to the lack of shift invariance on Riemannian manifolds\n",
    "\n",
    "#### Examples:\n",
    "[6] Spectral Networks And Deep Locally Connected Networks on Graphs: Efficient deep NN architecture that uses two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian.\n",
    "\n",
    "This paper proposes **Geodesic Convolution Neural Network**, combining the benefits of **intrinsic sturctures** and **deep learning**. It is a extension of of the CNN paradigm to non-Euclidean manifolds based on local geodesic system of coordinates that are analogous to ‘patches’ in images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f072b-4d54-4926-a3b2-2eda81dc679e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## II. Background and Model\n",
    "\n",
    "**Geodesic Convolution Neural Network** uses local system of geodesic polar coordinates at x\n",
    "1. p-level set of geodesic distance function $d_{X} (x, \\xi )$, truncated at $\\rho_{0}$\n",
    "2. points along geodesic $\\Gamma_{\\theta}(x)$ emanating from x in direction $\\theta$\n",
    "\n",
    "Local chart: bijective map <br>\n",
    "\n",
    "$\\Omega (x) : B_{\\rho_{0}} (x) \\rightarrow [0, \\rho_{0}] \\times [0, 2\\Pi]$\n",
    "\n",
    "from manifold to local coordinates\n",
    "($\\rho$, $\\theta$) around x\n",
    "\n",
    "**Patch operator** applied to $f \\in L^2 (X)$ <br>\n",
    "$(D(x)f)(\\rho , \\theta) = (f o \\Omega ^(-1)(x))(\\rho , \\theta)$             \n",
    "                \n",
    "<figure>\n",
    "<img src = 'img/geodesic_coor.png' width=\"300\">\n",
    "<figcaption align = \"center\"><b>Fig. 2 local system examples</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src = 'img/patch_operator.png' width=\"600\">\n",
    "<figcaption align = \"center\"><b>Fig. 3 Path Operator Construction</b></figcaption>\n",
    "</figure> \n",
    "\n",
    "\n",
    "## Geodesic Convolution \n",
    "GC applys filter a to patches extracted from $f \\in L^2 (X)$ in local geodesic polar coordinates \n",
    "\n",
    "$(f*a)(x) = \\sum_{\\theta , r} (D(x)f)(r,\\theta) \\alpha (\\theta , r)$\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src = 'img/geodesic_convolution.png' width=\"600\">\n",
    "<figcaption align = \"center\"><b>Fig. 4 Geodesic Convolution</b></figcaption>\n",
    "</figure> \n",
    "\n",
    "\n",
    "### Geodesic Convolution Layer\n",
    "\n",
    "<figure>\n",
    "<img src = 'img/convolution_layer.png' width=\"600\">\n",
    "<figcaption align = \"center\"><b>Fig. 4 Geodesic Convolution Layer</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Add Max Pooling Layer (remove rotation ambiguity)\n",
    "\n",
    "<figure>\n",
    "<img src = 'img/max_pooling.png' width=\"600\">\n",
    "<figcaption align = \"center\"><b>Fig. 4 Geodesic Convolution Layer</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "## Geodesic Convolution Neural Network Architecture\n",
    "<figure>\n",
    "<img src = 'img/GCNN.png' width=\"600\">\n",
    "<figcaption align = \"center\"><b>Fig. 4 Geodesic Convolution Layer</b></figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee312df7-7e25-4e65-aad2-1fdc966a959f",
   "metadata": {},
   "source": [
    "## III. Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a2998bb-ff41-4f57-830a-227ea4c40ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.sparse as Tsp\n",
    "\n",
    "import lasagne as L\n",
    "import lasagne.layers as LL\n",
    "import lasagne.objectives as LO\n",
    "from lasagne.layers.normalization import batch_norm\n",
    "\n",
    "sys.path.append('..')\n",
    "from icnn import utils_lasagne, dataset, snapshotter\n",
    "\n",
    "import geomstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ed749b-ca97-4366-84b8-bad23ff830d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianwu/opt/anaconda3/lib/python3.9/site-packages/theano/tensor/nnet/conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n",
      "  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n"
     ]
    }
   ],
   "source": [
    "# Network Defination\n",
    "nin = 544\n",
    "nclasses = 6890\n",
    "l2_weight = 1e-5\n",
    "\n",
    "def get_model(inp, patch_op):\n",
    "    icnn = LL.DenseLayer(inp, 16)\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 16, nrings=5, nrays=16))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 32, nrings=5, nrays=16))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 64, nrings=5, nrays=16))\n",
    "    ffn = batch_norm(LL.DenseLayer(icnn, 512))\n",
    "    ffn = LL.DenseLayer(icnn, nclasses, nonlinearity=utils_lasagne.log_softmax)\n",
    "\n",
    "    return ffn\n",
    "\n",
    "inp = LL.InputLayer(shape=(None, nin))\n",
    "patch_op = LL.InputLayer(input_var=Tsp.csc_fmatrix('patch_op'), shape=(None, None))\n",
    "\n",
    "ffn = get_model(inp, patch_op)\n",
    "\n",
    "# L.layers.get_output -> theano variable representing network\n",
    "output = LL.get_output(ffn)\n",
    "pred = LL.get_output(ffn, deterministic=True)  # in case we use dropout\n",
    "\n",
    "# target theano variable indicatind the index a vertex should be mapped to wrt the latent space\n",
    "target = T.ivector('idxs')\n",
    "\n",
    "# to work with logit predictions, better behaved numerically\n",
    "cla = utils_lasagne.categorical_crossentropy_logdomain(output, target, nclasses).mean()\n",
    "acc = LO.categorical_accuracy(pred, target).mean()\n",
    "\n",
    "# a bit of regularization is commonly used\n",
    "regL2 = L.regularization.regularize_network_params(ffn, L.regularization.l2)\n",
    "\n",
    "\n",
    "cost = cla + l2_weight * regL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2d7de90-f2ab-4850-b535-bbd21a10ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Rule Defination\n",
    "\n",
    "params = LL.get_all_params(ffn, trainable=True)\n",
    "grads = T.grad(cost, params)\n",
    "# computes the L2 norm of the gradient to better inspect training\n",
    "grads_norm = T.nlinalg.norm(T.concatenate([g.flatten() for g in grads]), 2)\n",
    "\n",
    "# Adam turned out to be a very good choice for correspondence\n",
    "updates = L.updates.adam(grads, params, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda1b85-df45-4774-8a95-6098f1f30360",
   "metadata": {},
   "source": [
    "## IV. Demonstration and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dab8b-bc53-4213-8708-3716d46d7524",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset used is called MPI Dynamic FAUST [7]. It is a 4D scan of human moving captured over time. FAUST shapes contained 6.8K points. All shapes were scaled to unit geodesic diameter.\n",
    "\n",
    "It contains 100 scans with 10 poses <br>\n",
    "<figure>\n",
    "<img src = 'img/train_images.png' width=\"800\">\n",
    "<figcaption align = \"center\"><b>Fig. 5 10 poses in the training dataset</b></figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "269b7c06-47d2-4e1d-a587-b68adcda2e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'FAUST_registrations_train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ls/88s14scx2r1cwsmhbts_nw480000gn/T/ipykernel_35186/2525422192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/FAUST_registrations/data/diam=200/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m ds = dataset.ClassificationDatasetPatchesMinimal(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m'FAUST_registrations_train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FAUST_registrations_test.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'descs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ECE594N/hw3/icnn/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_txt, test_txt, descs_path, patches_path, geods_path, labels_path, desc_field, patch_field, geod_field, label_field, epoch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FAUST_registrations_train.txt'"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "base_path = '/FAUST_registrations/data/diam=200/'\n",
    "\n",
    "ds = dataset.ClassificationDatasetPatchesMinimal(\n",
    "    'FAUST_registrations_train.txt', 'FAUST_registrations_test.txt',\n",
    "    os.path.join(base_path, 'descs', 'shot'),\n",
    "    os.path.join(base_path, 'patch_aniso', 'alpha=100_nangles=016_ntvals=005_tmin=6.000_tmax=24.000_thresh=99.900_norm=L1'), \n",
    "    None, \n",
    "    os.path.join(base_path, 'labels'),\n",
    "    epoch_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d41d3-e87a-4347-afbd-523173fd5708",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0de82b96-2e06-493f-858c-029d5bef6ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'demo_training.snap', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ls/88s14scx2r1cwsmhbts_nw480000gn/T/ipykernel_35186/564594696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mkvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnapshotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSnapshotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'demo_training.snap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit_count\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ECE594N/hw3/icnn/snapshotter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} Opening DB {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    443\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    444\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'demo_training.snap', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "eval_freq = 1\n",
    "\n",
    "start_time = time.time()\n",
    "best_trn = 1e5\n",
    "best_tst = 1e5\n",
    "\n",
    "kvs = snapshotter.Snapshotter('demo_training.snap')\n",
    "\n",
    "for it_count in xrange(n_epochs):\n",
    "    tic = time.time()\n",
    "    b_l, b_c, b_s, b_r, b_g, b_a = [], [], [], [], [], []\n",
    "    for x_ in ds.train_iter():\n",
    "        tmp = funcs['train'](*x_)\n",
    "\n",
    "        # do some book keeping (store stuff for training curves etc)\n",
    "        b_l.append(tmp[0])\n",
    "        b_c.append(tmp[1])\n",
    "        b_r.append(tmp[2])\n",
    "        b_g.append(tmp[3])\n",
    "        b_a.append(tmp[4])\n",
    "    epoch_cost = np.asarray([np.mean(b_l), np.mean(b_c), np.mean(b_r), np.mean(b_g), np.mean(b_a)])\n",
    "    print(('[Epoch %03i][trn] cost %9.6f (cla %6.4f, reg %6.4f), |grad| = %.06f, acc = %7.5f %% (%.2fsec)') %\n",
    "                 (it_count, epoch_cost[0], epoch_cost[1], epoch_cost[2], epoch_cost[3], epoch_cost[4] * 100, \n",
    "                  time.time() - tic))\n",
    "\n",
    "    if np.isnan(epoch_cost[0]):\n",
    "        print(\"NaN in the loss function...let's stop here\")\n",
    "        break\n",
    "\n",
    "    if (it_count % eval_freq) == 0:\n",
    "        v_c, v_a = [], []\n",
    "        for x_ in ds.test_iter():\n",
    "            tmp = funcs['acc_loss'](*x_)\n",
    "            v_a.append(tmp[0])\n",
    "            v_c.append(tmp[1])\n",
    "        test_cost = [np.mean(v_c), np.mean(v_a)]\n",
    "        print(('           [tst] cost %9.6f, acc = %7.5f %%') % (test_cost[0], test_cost[1] * 100))\n",
    "\n",
    "        if epoch_cost[0] < best_trn:\n",
    "            kvs.store('best_train_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_trn = epoch_cost[0]\n",
    "        if test_cost[0] < best_tst:\n",
    "            kvs.store('best_test_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_tst = test_cost[0]\n",
    "print(\"...done training %f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc91c7-733a-4754-8c32-4888279ca91d",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f6afe-b069-4368-a7b5-3b93aea8234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite = True\n",
    "\n",
    "out_path = '/outputs' \n",
    "print \"Saving output to: %s\" % out_path\n",
    "\n",
    "if not os.path.isdir(out_path) or rewrite==True:\n",
    "    try:\n",
    "        os.makedirs(out_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    a = []\n",
    "    for i,d in enumerate(ds.test_iter()):\n",
    "        fname = os.path.join(out_path, \"%s\" % ds.test_fnames[i])\n",
    "        print fname,\n",
    "        tmp = funcs['predict'](d[0], d[1])[0]\n",
    "        a.append(np.mean(np.argmax(tmp, axis=1).flatten() == d[2].flatten()))\n",
    "        scipy.io.savemat(fname, {'desc': tmp})\n",
    "        print \", Acc: %7.5f %%\" % (a[-1] * 100.0)\n",
    "    print \"\\nAverage accuracy across all shapes: %7.5f %%\" % (np.mean(a) * 100.0)\n",
    "else:\n",
    "    print \"Model predictions already produced.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466453c3-7c90-42bc-8df3-9a1f6c7bb9cb",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "\n",
    "I was not able to reproduce the output of the paper. The dataset that was used requires a lot more preprocesssing. I have tried incorporating code from the author [9] but with no luck. Below is the anlaysis I did from the results of the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb185cd9-4d6a-4985-91e6-3ef843ee0213",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Acoording to the paper, GCNN is more robust to previous attempts(including Random forest, functional map, and blended maps). It achieves higher percent of correct correspondance\n",
    "<figure>\n",
    "<img src = 'img/geodesic_radius.png' width=\"800\">\n",
    "<figcaption align = \"center\"><b>Fig. 6 Performance of shape correspondence using Princeton Benchmark</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "In Figure 7, you can see GCNN has a better performance on matching corresponding body parts than random forrest.\n",
    "\n",
    "<figure>\n",
    "<img src = 'img/gcc_vs_rf.png' width=\"800\">\n",
    "<figcaption align = \"center\"><b>Fig. 7 GCNN (bottom) vs random forest(top)</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src = 'img/precision.png' width=\"800\">\n",
    "<figcaption align = \"center\"><b>Fig. 8 Performance (in terms of Precision-Recall) of shape retrieval on the FAUST</b></figcaption>\n",
    "</figure>\n",
    "\n",
    "In conclusion, GCNN is a flexible and effective solution for shape analysis. It be used to solve both simple and complex problems by adjusting the amount of concollution layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f8d99-c94f-4335-a858-d13cbc36046b",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[1] A. E. Johnson and M. Hebert. Using spin images for efficient object recognition in cluttered 3D scenes. PAMI, 21(5):433– 449, 1999. <br>\n",
    "[2] S. Manay et al. Integral invariants for shape matching. PAMI, 28(10):1602–1618, 2006.<br>\n",
    "[3] D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91–110, 2004.<br>\n",
    "[4] J. Sun, M. Ovsjanikov, and L. J. Guibas. A concise and provably informative multi-scale signature based on heat diffusion.CGF, 28(5):1383–1392, 2009.<br>\n",
    "[5] M. Aubry, U. Schlickewei, and D. Cremers. The wave kernel signature: A quantum mechanical approach to shape analysis. In Proc. ICCV, 2011.<br>\n",
    "[6] J. Bruna et al. Spectral networks and locally connected networks on graphs. In Proc. ICLR, 2014.<br>\n",
    "[7] F. Bogo et al. FAUST: Dataset and evaluation for 3D mesh registration. In Proc. CVPR, 2014.F. Bogo et al. FAUST: Dataset and evaluation for 3D mesh registration. In Proc. CVPR, 2014.<br>\n",
    "[8] Miolane, Nina, et al. \"Geomstats: a Python package for Riemannian geometry in machine learning.\" Journal of Machine Learning Research 21.223 (2020)\n",
    "[9] https://github.com/jonathanmasci/EG16_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616d670-d746-4bc2-a141-08895f3aed36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce3de9-b87a-491d-b8b9-009b615c8e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be880f9-4297-4179-96d1-4202d58e0c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
