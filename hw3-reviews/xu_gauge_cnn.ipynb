{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000d2ffe",
   "metadata": {},
   "source": [
    "# Gauge Equivariant Convolutional Networks and the Icosahedral CNN\n",
    "Authors: Zheng Xu\n",
    "## 1. Introduction and Motivation\n",
    "\n",
    "Nowadays, deep learning lead by intuition-guided experimentation has achieved great success, but it has not solved the problem that we can not understand why and when certain architectures work well. So every new application of deep learning requires a lot of labor and energy cost to do an extensive architecture search. People seek for general principles to guide architechture search, and one successfull design principle states that network architectures should be equivariant to symmetries.\n",
    "\n",
    "Equivariant networks have been developed for sets, graphs, and homogeneous spaces like the sphere. In each case, the network is made equivariant to the global symmetries of the underlying space. However, manifolds do not usually have global symmetries, so it's not common to develop equivariant CNNs for manifolds.\n",
    "\n",
    "General manifolds have local gauge symmetries, which is crucial for building manifold CNNs that depend only on intrinsic geometry. In this paper, the author define a convolution-like operation on general manifolds M that is equivariant to local gauge transformations. The type of inputs and outputs are all feature fields. Each field represented by a number of new feature maps, whose activations are coefficients of a geometrical object. So if the gauge changed, the coefficients change in a predictable way so as to preserve their geometrical meaning, which turns the problem for searching for a geometrically natural definition of \"manifold convolution\" to gauge equivariance.\n",
    "\n",
    "Furthurmore, this paper apply the gauge equivariant networks on one specific manifold: the icosehedron. This manifold has some global symmetries(discrete rotations), and the regularity and local flatness of this manifold allows for a very efficient implementation using exsiting deep learning primitives(conv2d).\n",
    "\n",
    "## 2. Related work\n",
    "### Equivariant Deep Learning \n",
    "Equivariant networks have been proposed for permutation-equivariant analysis and prediction of sets, graphs, translations and rotations of the plane and 3D space. In this paper the author generalize G-CNNs from homogeneous spaces to general manifolds. \n",
    "### Geometric Deep Learning\n",
    " Geometric Deep Learning Geometric deep learning is concerned with the generalization of (convolutional) neural networks to manifolds. Some of the manifold convolution are gauge equivariant. However, these methods are all limited to particular feature types $\\rho$ (typically scalar), and/or use a parameterization of the kernel that is not maximally flexible.\n",
    "\n",
    "### Spherical CNNs\n",
    "The Icosahedral CNN can be viewed as a fast and simple alternative to Spherical CNNs.Use a spherical grid based on a subvision of the icosahedron, and convolve over it.\n",
    "\n",
    "## 3. Implemention of icosahedral CNN\n",
    "Firstly, the article introduces the gauges, gauge transformations, and the exponential map. The article defines gauge as a position-dependent invertible linear map $w_{p}: \\mathbb{R}^{d} \\rightarrow T_{p} M$, where $T_{p} M$ is the tangent space of $M$ at $p$. A gauge transformation is a position-dependent change of frame, which can be described by maps $g_{p} \\in$ $\\mathrm{GL}(d, \\mathbb{R})$ (the group of invertible $d \\times d$ matrices).The exponential map gives a convenient parameterization of the local neighbourhood of $p \\in M$. This map $\\exp _{p}: T_{p} M \\rightarrow M$ takes a tangent vector $V \\in T_{p} M$, follows the geodesic (shortest curve) in the direction of $V$ with speed $\\|V\\|$ for one unit of time, to arrive at a point $q=\\exp _{p} V$ .\n",
    "\n",
    "Next part is about defining gauge equivariant convolution. Begin with scalar input and output fields. Define a filter as a locally supported function $K: \\mathbb{R}^{d} \\rightarrow$ $\\mathbb{R}$, where $\\mathbb{R}^{d}$ may be identified with $T_{p} M$ via the gauge $w_{p}$. Then, writing $q_{v}=\\exp _{p} w_{p}(v)$ for $v \\in \\mathbb{R}^{d}$, we define the scalar convolution of $K$ and $f: M \\rightarrow \\mathbb{R}$ at $p$ as follows:\n",
    "$$\n",
    "(K \\star f)(p)=\\int_{\\mathbb{R}^{d}} K(v) f\\left(q_{v}\\right) d v\n",
    "$$\n",
    "\n",
    "In general case, the transformation behaviour of a $C$ dimensional geometrical quantity is described by a representation of the structure group $G$. This is a mapping $\\rho: G \\rightarrow \\operatorname{GL}(C, \\mathbb{R})$ that satisfies $\\rho(g h)=\\rho(g) \\rho(h)$. For general fields, consider a stack of $C_{\\text {in }}$ input feature maps on $M$, which represents a $C_{\\text {in }}$-dimensional $\\rho_{\\text {in }}$-field, and define a convolutional operation that output a $C_{\\text {out }}$-dimensional $\\rho_{\\text {out }}$-field. Then describe the filter bank as a matrix-valued kernel $K: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{C_{\\text {out }} \\times C_{\\text {in }}}$.Thus we can get the generalized form for general fields:\n",
    "$$\n",
    "(K \\star f)(p)=\\int_{\\mathbb{R}^{d}} K(v) \\rho_{\\text {in }}\\left(g_{p \\leftarrow q_{v}}\\right) f\\left(q_{v}\\right) d v .\n",
    "$$\n",
    "\n",
    "Under a gauge transformation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v & \\mapsto g_{p}^{-1} v, & f\\left(q_{v}\\right) & \\mapsto \\rho_{\\text {in }}\\left(g_{q_{v}}^{-1}\\right) f\\left(q_{v}\\right), \\\\\n",
    "w_{p} & \\mapsto w_{p} g_{p}, & g_{p \\leftarrow q_{v}} & \\mapsto g_{p}^{-1} g_{p \\leftarrow q_{v}} g_{q_{v}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Gauge equivariant convolution on the icosahedron is implemented in three steps: G-Padding, kernel expansion, and 2d convolution/HexaConv. If the output is to be of the same size as the input, we zero padding.In this paper, instead of zero padding, we copy the pixels from the neighbouring chart. The transformation $g_{i j}(p)$ acts on the feature vector at $p$ via the matrix $\\rho\\left(g_{i j}(p)\\right)$, where $\\rho$ is the representation of $G=$ $C_{6}$ associated with the feature space under consideration. In this work we only consider two kinds of representations: scalar features with $\\rho(g)=1$, and regular features with $\\rho$ equal to the regular representation:\n",
    "\n",
    "$$\n",
    "\\rho(2 \\pi / 6)=\\left[\\begin{array}{llllll}\n",
    "0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "1 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "That is, a cyclic permutation of 6 elements. Since $2 \\pi / 6$ is a generator of $C_{6}$, the value of $\\rho$ at the other group elements is determined by this matrix: $\\rho(k \\cdot 2 \\pi / 6)=\\rho(2 \\pi / 6)^{k}$. If the feature vector consists of multiple scalar or regular features, we would have a block-diagonal matrix $\\rho\\left(g_{i j}(p)\\right)$.\n",
    "\n",
    "The article implements G-padding by indexing operations on the feature maps. For each position $p$ to be padded, the author precompute $g_{i j}(p)$, which can be $+1 \\cdot (2 \\pi / 6)$ or 0 or $-1 \\cdot (2 \\pi / 6)$. We use these to precompute four indexing operations (for the top, bottom, left and right side of the charts).\n",
    "\n",
    "For the convolution to be gauge equivariant, the kernel must satisfy:\n",
    "$$\n",
    "(K \\star f)(p)=\\int_{\\mathbb{R}^{d}} K(v) \\rho_{\\text {in }}\\left(g_{p \\leftarrow q_{v}}\\right) f\\left(q_{v}\\right) d v .\n",
    "$$\n",
    ". The kernel $K: \\mathbb{R}^{2} \\rightarrow \\mathbb{R}^{R_{\\text {out }} C_{\\text {out }} \\times R_{\\text {in }} C_{\\text {in }}}$ is stored in an array of shape $\\left(R_{\\text {out }} C_{\\text {out }}, R_{\\text {in }} C_{\\text {in }}, 3,3\\right)$, with the top-right and bottom-left pixel of each $3 \\times 3$ filter fixed at zero so that it corresponds to a 1-ring hexagonal kernel.\n",
    "Weight sharing can be implemented by constructing a basis of kernels, each of which has shape $\\left(R_{\\text {out }}, R_{\\mathrm{in}}, 3,3\\right)$ and has value 1 at all pixels of a certain color/shade, and 0 elsewhere. Then one can construct the full kernel by linearly combining these basis filters using learned weights (one for each $C_{\\text {in }} \\cdot C_{\\text {out }}$ input/output channels and basis kernel).\n",
    "\n",
    "## 4. Algorithm\n",
    "The algorithm is shown as:\n",
    "$$\n",
    "\\operatorname{GConv}(\\mathrm{f}, \\mathrm{w})=\\operatorname{conv} 2 \\mathrm{~d}(\\mathrm{GPad}(\\mathrm{f}), \\operatorname{expand}(\\mathrm{w}))\n",
    "$$\n",
    "Where $f$ and $\\operatorname{GPad}(f)$ both have shape $\\left(B, C_{\\text {in }} R_{\\text {in }}, 5 H, W\\right)$, the weights $w$ have shape $\\left(C_{\\text {out }}, C_{\\text {in }} R_{\\text {in }}, 7\\right)$, and expand $(w)$ has shape $\\left(C_{\\text {out }} R_{\\text {out }}, C_{\\text {in }} R_{\\text {in }}, 3,3\\right)$. The output of GConv has shape $\\left(B, C_{\\text {out }} R_{\\text {out }}, 5 H, W\\right)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631a724e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geomstats in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (2.4.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from geomstats) (1.7.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from geomstats) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.4 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from geomstats) (3.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from geomstats) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from geomstats) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from geomstats) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.4->geomstats) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.4->geomstats) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.4->geomstats) (2.8.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.4->geomstats) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.4->geomstats) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.3.4->geomstats) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->geomstats) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/xuzheng/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.1->geomstats) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geomstats\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geomstats.backend as gs\n",
    "import geomstats.visualization as visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install https://github.com/DavidDiazGuerra/icoCNN/zipball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435005c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .icoCNN import *\n",
    "from .icoGrid import icosahedral_grid_coordinates\n",
    "\n",
    "import icoCNN.tools\n",
    "import icoCNN.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .icoCNN import *\n",
    "from .icoGrid import icosahedral_grid_coordinates\n",
    "\n",
    "import icoCNN.tools\n",
    "import icoCNN.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f7a40b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    def forward(self, x):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import einops\n",
    "from math import sqrt\n",
    "\n",
    "__all__ = [\"CleanVertices\", \"SmoothVertices\", \"PadIco\", \"ConvIco\", \"PoolIco\", \"LNormIco\"]\n",
    "\n",
    "\n",
    "class CleanVertices(torch.nn.Module):\n",
    "\"\"\" \n",
    "r : Resolution of the input icosahedral signal\n",
    "Input : [..., 5, 2^r, 2^(r+1)]\n",
    "Output : [..., 5, 2^r, 2^(r+1)]\n",
    "\"\"\"\n",
    "def __init__(self, r):\n",
    "        super().__init__()\n",
    "        self.register_buffer('mask', torch.ones((2**r, 2**(r+1))))\n",
    "        self.mask[0, 0] = 0\n",
    "        self.mask[0, 2**r] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.mask\n",
    "\n",
    "\n",
    "class SmoothVertices(torch.nn.Module):\n",
    "    def __init__(self, r):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "        self.clear_vertices = CleanVertices(r)\n",
    "        self.v1_neighbors = torch.LongTensor([[[chart, 1, 0],\n",
    "                                                [chart, 1, 1],\n",
    "                                                [chart, 0, 1],\n",
    "                                                [chart-1, -1, 2**r],\n",
    "                                                [chart-1, -1, 2**r-1]] for chart in range(5)])\n",
    "        self.v2_neighbors = torch.LongTensor([[[chart, 1, 2**r],\n",
    "                                                [chart, 1, 2**r + 1],\n",
    "                                                [chart, 0, 2**r + 1],\n",
    "                                                [chart-1, -1, -1],\n",
    "                                                [chart, 0, 2**r-1]] for chart in range(5)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.clear_vertices(x)\n",
    "        x[..., 0, 0] += einops.reduce(x[...,\n",
    "                                        self.v1_neighbors[..., 0],\n",
    "                                        self.v1_neighbors[..., 1],\n",
    "                                        self.v1_neighbors[..., 2]],\n",
    "                                        '... R charts neighbors -> ... 1 charts', 'mean')\n",
    "        x[..., 0, 2**self.r] += einops.reduce(x[...,\n",
    "                                                self.v2_neighbors[..., 0],\n",
    "                                                self.v2_neighbors[..., 1],\n",
    "                                                self.v2_neighbors[..., 2]],\n",
    "                                                '... R charts neighbors -> ... 1 charts', 'mean')\n",
    "        return x\n",
    "\n",
    "\n",
    "class PadIco(torch.nn.Module):\n",
    "    \"\"\" \n",
    "    r : int\n",
    "    R : int, 1 or 6\n",
    "        6 when the input signal includes the 6 kernel orientation channels or 1 if it doesn't\n",
    "    Input : [..., R, 5, 2^r, 2^(r+1)]\n",
    "    Output : [..., R, 5, 2^r+2, 2^(r+1)+2]\n",
    "    \"\"\"\n",
    "    def __init__(self, r, R, smooth_vertices=False, preserve_vertices=False):\n",
    "        super().__init__()\n",
    "        assert R==1 or R==6\n",
    "        self.R = R\n",
    "        self.r = r\n",
    "        self.H = 2**r\n",
    "        self.W = 2**(r+1)\n",
    "        self.smooth_vertices = smooth_vertices\n",
    "        if not preserve_vertices:\n",
    "            self.process_vertices = SmoothVertices(r) if smooth_vertices else CleanVertices(r)\n",
    "        else:\n",
    "            assert not smooth_vertices\n",
    "            self.process_vertices = lambda x: x\n",
    "        idx_in= torch.arange(R * 5 * self.H * self.W, dtype=torch.long).reshape(R, 5, self.H, self.W)\n",
    "        idx_out = torch.zeros((R, 5, self.H + 2, self.W + 2), dtype=torch.long)\n",
    "        idx_out[..., 1:-1, 1:-1] = idx_in\n",
    "        idx_out[..., 0, 1:2 ** r + 1] = idx_in.roll(1, -3)[..., -1, 2 ** r:]\n",
    "        idx_out[..., 0, 2 ** r + 1:-1] = idx_in.roll(1, -3).roll(-1, -4)[..., :, -1].flip(-1)\n",
    "        idx_out[..., -1, 2:2 ** r + 2] = idx_in.roll(-1, -3).roll(-1, -4)[..., :, 0].flip(-1)\n",
    "        idx_out[..., -1, 2 ** r + 1:-1] = idx_in.roll(-1, -3)[..., 0, 0:2 ** r]\n",
    "        idx_out[..., 1:-1, 0] = idx_in.roll(1, -3).roll(1, -4)[..., -1, 0:2 ** r].flip(-1)\n",
    "        idx_out[..., 2:, -1] = idx_in.roll(-1, -3).roll(1, -4)[..., 0, 2 ** r:].flip(-1)\n",
    "        self.reorder_idx = idx_out\n",
    "        def forward(self, x):\n",
    "        x = self.process_vertices(x)\n",
    "        if self.smooth_vertices:\n",
    "            smooth_north_pole = einops.reduce(x[..., -1, 0], '... R charts -> ... 1 1', 'mean')\n",
    "            smooth_south_pole = einops.reduce(x[..., 0, -1], '... R charts -> ... 1 1', 'mean')\n",
    "        x = einops.rearrange(x, '... R charts H W -> ... (R charts H W)', R=self.R, charts=5, H=self.H, W=self.W)\n",
    "        y = x[..., self.reorder_idx]\n",
    "        if self.smooth_vertices:\n",
    "            y[..., -1, 1] = smooth_north_pole\n",
    "            y[..., 1, -1] = smooth_south_pole\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class ConvIco(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, r, Cin, Cout, Rin, Rout=6, bias=True, smooth_vertices=False):\n",
    "        super().__init__()\n",
    "        assert Rin == 1 or Rin == 6\n",
    "        self.r = r\n",
    "        self.Cin = Cin\n",
    "        self.Cout = Cout\n",
    "        self.Rin = Rin\n",
    "        self.Rout = Rout\n",
    "\n",
    "        self.process_vertices = SmoothVertices(r) if smooth_vertices else CleanVertices(r)\n",
    "        self.padding = PadIco(r, Rin, smooth_vertices=smooth_vertices)\n",
    "\n",
    "        s = sqrt(2 / (3 * 3 * Cin * Rin))\n",
    "        self.weight = torch.nn.Parameter(s * torch.randn((Cout, Cin, Rin, 7)))  # s * torch.randn((Cout, Cin, Rin, 7))  #\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.zeros(Cout))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.kernel_expansion_idx = torch.zeros((Cout, Rout, Cin, Rin, 9, 4), dtype=int)\n",
    "        self.kernel_expansion_idx[..., 0] = torch.arange(Cout).reshape((Cout, 1, 1, 1, 1))\n",
    "        self.kernel_expansion_idx[..., 1] = torch.arange(Cin).reshape((1, 1, Cin, 1, 1))\n",
    "        idx_r = torch.arange(0, Rin)\n",
    "        idx_k = torch.Tensor(((5, 4, -1, 6, 0, 3, -1, 1, 2),\n",
    "                                (4, 3, -1, 5, 0, 2, -1, 6, 1),\n",
    "                                (3, 2, -1, 4, 0, 1, -1, 5, 6),\n",
    "                                (2, 1, -1, 3, 0, 6, -1, 4, 5),\n",
    "                                (1, 6, -1, 2, 0, 5, -1, 3, 4),\n",
    "                                (6, 5, -1, 1, 0, 4, -1, 2, 3)))\n",
    "        for i in range(Rout):\n",
    "            self.kernel_expansion_idx[:, i, :, :, :, 2] = idx_r.reshape((1, 1, Rin, 1))\n",
    "            self.kernel_expansion_idx[:, i, :, :, :, 3] = idx_k[i,:]\n",
    "            idx_r = idx_r.roll(1)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"r={}, Cin={}, Cout={}, Rin={}, Rout={}, bias={}\"\\\n",
    "            .format(self.r, self.Cin, self.Cout, self.Rin, self.Rout, self.bias is not None)\n",
    "\n",
    "    def get_kernel(self):\n",
    "        kernel = self.weight[self.kernel_expansion_idx[..., 0],\n",
    "                                self.kernel_expansion_idx[..., 1],\n",
    "                                self.kernel_expansion_idx[..., 2],\n",
    "                                self.kernel_expansion_idx[..., 3]]\n",
    "        kernel = kernel.reshape((self.Cout, self.Rout, self.Cin, self.Rin, 3, 3))\n",
    "        kernel[..., 0, 2] = 0\n",
    "        kernel[..., 2, 0] = 0\n",
    "        return kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.padding(x)\n",
    "        x = einops.rearrange(x, '... C R charts H W -> ... (C R) (charts H) W', C=self.Cin, R=self.Rin, charts=5)\n",
    "        if x.ndim == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "            remove_batch_size = True\n",
    "        else:\n",
    "            remove_batch_size = False\n",
    "            batch_shape = x.shape[:-3]\n",
    "            x = x.reshape((-1,) + x.shape[-3:])\n",
    "\n",
    "        kernel = self.get_kernel()\n",
    "        kernel = einops.rearrange(kernel, 'Cout Rout Cin Rin Hk Wk -> (Cout Rout) (Cin Rin) Hk Wk', Hk=3, Wk=3)\n",
    "        bias = einops.repeat(self.bias, 'Cout -> (Cout Rout)', Cout=self.Cout, Rout=self.Rout) \\\n",
    "            if self.bias is not None else None\n",
    "\n",
    "        y = torch.nn.functional.conv2d(x, kernel, bias, padding=(1, 1))\n",
    "        y = einops.rearrange(y, '... (C R) (charts H) W -> ... C R charts H W', C=self.Cout, R=self.Rout, charts=5)\n",
    "        y = y[..., 1:-1, 1:-1]\n",
    "        if remove_batch_size: y = y[0, ...]\n",
    "        else: y = y.reshape(batch_shape + y.shape[1:])\n",
    "\n",
    "        return self.process_vertices(y)\n",
    "\n",
    "class PoolIco(torch.nn.Module):\n",
    "    def __init__(self, r, R, function=torch.mean, smooth_vertices=False):\n",
    "        super().__init__()\n",
    "        self.function = function\n",
    "        self.padding = PadIco(r, R, smooth_vertices=smooth_vertices)\n",
    "        self.process_vertices = SmoothVertices(r-1) if smooth_vertices else CleanVertices(r-1)\n",
    "        self.neighbors = torch.zeros((2**(r-1), 2**r, 7, 2), dtype=torch.long)\n",
    "        for h in range(self.neighbors.shape[0]):\n",
    "            for w in range(self.neighbors.shape[1]):\n",
    "                self.neighbors[h,w,...] = torch.Tensor([[1+2*h,   1+2*w  ],\n",
    "                                                        [1+2*h+1, 1+2*w  ],\n",
    "                                                        [1+2*h+1, 1+2*w+1],\n",
    "                                                        [1+2*h,   1+2*w+1],\n",
    "                                                        [1+2*h-1, 1+2*w  ],\n",
    "                                                        [1+2*h-1, 1+2*w-1],\n",
    "                                                        [1+2*h,   1+2*w-1]])\n",
    "\n",
    "def forward(self, x):\n",
    "        x = self.padding(x)\n",
    "        receptive_field = x[..., self.neighbors[...,0], self.neighbors[...,1]]\n",
    "        y = self.function(receptive_field, -1)\n",
    "        return self.process_vertices(y)\n",
    "\n",
    "class LNormIco(torch.nn.Module):\n",
    "    def __init__(self, C, R):\n",
    "        super().__init__()\n",
    "        self.norm = torch.nn.LayerNorm((C, R), elementwise_affine=False)\n",
    "        self.weight = torch.nn.Parameter(torch.ones((C, 1)))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((C, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = einops.rearrange(x, \"... C R charts H W -> ... charts H W C R\")\n",
    "        original_shape = x.shape\n",
    "        x = einops.rearrange(x, \"... charts H W C R -> (... charts H W) C R\")\n",
    "        x = self.norm(x)\n",
    "        x = x * self.weight + self.bias\n",
    "        x = x.reshape(original_shape)\n",
    "        x = einops.rearrange(x, \"... charts H W C R -> ... C R charts H W\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ff1e8",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We can compare the Icosahedral CNN with the original Spherical CNN. The Spherical CNN uses feature maps on the sphere $S^{2}$ and rotation group $\\mathrm{SO}(3)$ (the latter of which can be thought of a regular field on the sphere), sampled on the SOFT grids defined by (Kostelec \\& Rockmore, 2007), which have shape $2 B \\times 2 B$ and $2 B \\times 2 B \\times 2 B$, respectively (here $B$ is the bandwidth / resolution parameter). Specifically, the grid points are:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_{j_{1}} &=\\frac{2 \\pi j_{1}}{2 B}, \\\\\n",
    "\\beta_{k} &=\\frac{\\pi(2 k+1)}{4 B}, \\\\\n",
    "\\gamma_{j_{2}} &=\\frac{2 \\pi j_{2}}{2 B}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\left(\\alpha_{j_{1}}, \\beta_{k}\\right)$ form a spherical grid and $\\left(\\alpha_{j_{1}}, \\beta_{k}, \\gamma_{j_{2}}\\right)$ form an $\\mathrm{SO}(3)$ grid (for $j_{1}, k, j_{2}=0, \\ldots 2 B-1$ ). These grids have two downsides.\n",
    "\n",
    "Firstly, to get a sufficiently high sampling near the equator, we are forced to oversample the poles, and thus waste computational resources. For almost all applications, a more homogeneous grid is more suitable.\n",
    "\n",
    "The second downside of the SOFT grid on $\\operatorname{SO}(3)$ is that we increase the resolution of the spherical image, the number of rotations applied to each filter is increased as well, which is undesirable.\n",
    "\n",
    "The grid used in the Icosahedral CNN addresses both concerns. It is spatially very homogeneous, and we apply the filters in 6 orientations, regardless of spatial resolution.\n",
    "\n",
    "The $\\mathrm{SO}(3)$ convolution (used in most layers of a typical Spherical CNN) has complexity $O\\left(B^{3} \\log B\\right)$ which compares favorably to the naive $O\\left(B^{6}\\right)$ spatial implementation. If we use filters with a fixed (and usually small) size, the complexity of a naive spatial implementation reduces to $O\\left(B^{3}\\right)$, which is slightly better. Furthermore, because the Icosahedral CNN uses a fixed number of orientations per filter , its computational complexity is even better: it is linear in the number of pixels of the grid, and so comparable to $O\\left(B^{2}\\right)$ for the SOFT grid.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
