{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rebecca_Martin-HW3_Bioshapes.ipynb","provenance":[],"authorship_tag":"ABX9TyMEOU4+twoLFfnWzY8dtsKa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Protein Representations for Machine Learning Applications**\n","\n","# I. Introduction\n","\n","In the last few decades, there has been an explosion of interest in proteins. For good reason - understanding how proteins work, their folding and interactions, is critical to understanding fundamental aspects of biology, and this understanding can be transferred to boundless biomedical applications. This boom in interest has grown alongside the developing field of machine learning, and the explosion of sequence data available makes this space ripe for innovation. To understand the intersection between protein analysis and machine learning, it is important to know the context that representational tools developed in. In this paper, *Learning Meaningful Representations of Protein Sequences*$^{1}$ is reviewed, supported by summaries of key citations undergirding the paper. Ideally through these analyses, a novice can gain an appreciation for the breadth and depth of the field, as well as understand why geometric approach presented in *Detlefsen et al.* could be a the next frontier in this space.\n"],"metadata":{"id":"zwnTeHJtJkte"}},{"cell_type":"markdown","source":["# II. Literature Review\n","\n","### Learning Meaningful Representations of Protein Sequences$^{1}$\n","Representation in machine learning refers to the way in which data is introduced to the model, and how that data is interpreted and portrayed; the extraction and learning of features, the use of distance functions and other such calculations determines the predictive success of the model. The process of representation reduces high-dimensional data to low-dimensions, allowing for the detection of patterns and anomalies. The selection of a given representation in a problem is critical to the success of a model, leading to the question: what constitutes the most meaningful representation of protein sequence in machine learning models? To address this problem, this paper assesses two applications of the representation of protein sequences: transfer learning and interpretable learning. Additionally, it examines and compares contemporary practices in representational learning, and demonstrates the value of representational geometry.\n"," \n","The paper first evaluates the context of transfer-learning, where pre-training and task learning are distinct phases that are frequently enmeshed with a fine-tuning model. Three models are considered - a LSTM$^{2}$ model, a Transformer$^{4}$ model and a dilated residual network (Resnet)$^{5}$ model, where either a fixed or a fine-tuned embedding model is considered; these are compared to pre-trained and randomly initiated representation models, as well as a naive one-hot encoded baseline. They discovered that fine-tuning a representation to a specific task resulted in overfitting, meaning that fixing the embedded model during task-training should be the default.\n"," \n","The next question posed by the researchers is how to aggregate local representations of a given protein into a global understanding of the entire sequence - standard approaches include averaging with uniform or learned attention, or using the maximum value. This paper compared the concatenation of local representations (Concat), avoiding aggregation altogether, to using a neural network with a low-dimensional Bottleneck$^{6}$, which would result in the learning of an optimal aggregation operation. It was discovered that the Bottleneck strategy outperforms other strategies, indicating that if global representations of proteins is needed, it should be learned rather than calculated.\n"," \n","<style>\n","  div {\n","    text-align: center;\n","  }\n","</style>\n"," \n","\n","<div>\n","<img src=https://drive.google.com/uc?id=1jn98BtqCmIXkjzjF0jokxS7LpN-ojpzw width=\"750\">\n","</div>\n","Image 1: In the upper row, LSTM, Resnet and Transformer models and Bottleneck aggregation are trained on a full corpus of protein data; the lower row shows the same, but with β-lactamase sequences. The final graph shows the application of a dense variational autoencoder (VAE).\n","\n","\n","The paper then considers using representation not only as a way to assess underlying trends in the data, but also as a way to visualize and interpret the data. This was done by using multiple sequence alignment techniques, and comparing the spatial locations of individual residues in a set of proteins of the same length. This was done with using the latent space of a Variational Autoencoder (VAE), an approach called the DeepSequence Model.$^{8}$ The models previous considered were tested against a full corpus of proteins as well as a set of proteins in β-lactamase family; little phylogenetic separation was shown by any model for the full corpus and only the Transformer, Resnet and to some extent the VAE models separate the β-lactamase sequences, but in different ways. The differences in separation demonstrate the fundamental impact on resulting representations, and no clear conclusion can be drawn.\n","\n","<style>\n","  div {\n","    text-align: center;\n","  }\n","</style>\n","\n","<div>\n","<img src=https://drive.google.com/uc?id=1BAcZUSOHfYnE_YaexegcBlcTGpGMY6PF width=\"750\">\n","</div>\n","Image 2: By measuring the expected distances between one-hot encoded proteins, the Riemannian metric demonstrates the use of visualizing the underlying manifold. Through this visualization and comparison to the phylogenetic tree, we can see that geodesics can be useful for interpolating protein.\n","\n"," \n","Using the VAE representation from the previous test, the phylogenetic tree is mapped onto the encoding, demonstrating that neural networks can be used as high capacity function estimators. This implies that the latent manifold is meaningful and useful when relying on representation for data interpretation. This idea is further explored by the use of Riemannian metrics instead of Euclidean representation, which can be misleading in representation. The authors use geodesic distances corresponding to the distance between one-hot encoded proteins, with the shortest path referring to curves of minimal energy change. This is shown to be a way to make the distances and interpolations between points in representational space to be made more meaningful and robust with respect to the underlying manifold. When overlaying the Euclidean and Riemannian mappings, the latter better reflects the phylogenetic tree, indicating that geodesics are well-suited for interpolating proteins. Additionally, geodesics provide more natural interpolations in a representational space by avoiding high-entropy regions.\n"," \n","This paper explores many avenues related to protein representation and its use in making biological predictions, examining standard approaches, comparing them and then applying geometric computation to develop more robust models. It demonstrates that there is still a need for bespoke choice of a representation, with a single protein representation for all tasks being unlikely, and weighs in on the value of preprocessing and pretraining. Finally, by utilizing Riemannian representation spaces, geodesic distances can be used to better understand the phylogenetic mapping of a protein than the usual Euclidean view. \n"],"metadata":{"id":"ZQxR5tG6Jk4l"}},{"cell_type":"markdown","source":["### Long Short-Term Memory$^{2}$\n","\n","Recurrent networks can store recent inputs through the form of activations - something that is referred to as \"short-term memory.\" However, learning what to put in short-term memory takes a lot of time and is ineffective. Using Back-propogation through time or real-time recurrent learning, error signals being back-propagated vanish or blow up, leading to oscillating weights and long time lags.\n"," \n","LSTM overcomes error back-flow problems, bridging longer time intervals even in noisy sequences, while still maintaining short time lag capabilities. This is done by an efficient, gradient-based algorithm, retaining constant error flow using internal states of special units.\n"," \n","The LSTM Memory Cell units expand on the constant error carousel CEC, which has a fixed self connection, with new features. The $j$-th memory cell is denoted by $c_{j}$. The input of the cell is protected from noisy data by the input gate unit, while the output gate unit protects other units from perturbations by irrelevant data in $c_{j}$. \n"," \n","<style>\n","  div {\n","    text-align: center;\n","  }\n","</style>\n"," \n","<div>\n","<img src=https://drive.google.com/uc?id=1jBiDDXwlfePIPWA2HL26-07RViL1xdg6 width=\"750\">\n","</div>\n","Figure 3: This image shows the structure of the LSTM cell and the equations that describe it. $W$ is the recurrent connection between the previous hidden layer and the current layer;  $U$ is the weight matrix that connects the inputs to the hidden layer. $\\widetilde{C}$ is a candidate hidden state, and $C$ is the internal memory of the unit. $^{3}$\n"," \n","Through the constant error flow in the constant error carousel CEC, the LSTM memory cell architecture, allowing for the bridging of very long time lags. The two gate units learn to open and close access to error flow through each memory cell, and the multiplicative gate protects the CEC from noisy data.\n"],"metadata":{"id":"qpQh3erlN1PZ"}},{"cell_type":"markdown","source":["### Attention is All You Need$^{4}$\n","\n","Convolutional Neural Networks (CNNs), the underlying architecture for many sequential computation architectures, fails to learn dependencies between distant positions. The Transformer overcomes this by reducing the number of operations, through the use of Multi-Head Attention. The Transformer is a model architecture that rejects recurrence and instead leans into attention mechanisms to connect inputs and outputs using global dependendencies. This allows for greater parallelization, accelerating the learning process.\n"," \n","<style>\n","  div {\n","    text-align: center;\n","  }\n","</style>\n"," \n","<div>\n","<img src=https://drive.google.com/uc?id=1IMfP4maMCrdDGtD3_vwWoarrv4UUuhjn width=\"750\">\n","</div>\n","Figure 4: Transformers feature an encoder/decoder architecture, where a sequential input is evaluated all at once, with no time-step considered in the embeddings. \n"," \n","Inputs are first embedded, and in an example from Natural Language Processing, each word in a sequence is mapped to points in space reflecting meaning. This turns the sequence of words into vectors, which are then modified using the positional encoding to reflect the difference in positional relationships of the words in the sequence. In the multi-headed attention block, the model determines what part of the input is important for conveying meaning and should be focused on, incorporating the \"attention\" aspect of the transformer. Then, the feed-forward net transformers the attention vectors into a form that is useful to the next block.\n"," \n","The second half of the transformer starts with an output corresponding to the input being used to train the network - for an example of NLP model used to translate English to French, an input could be an English sentence and the output would be the French translation. This translation is then embedded as a vector, the positional relevance of the sequence is \n","evaluated, and then the attention block determines what piece of the sequence is important to understanding the meaning of the output. \n"," \n","Then the input and output vectors are then compared against each other in the final piece of the Transformer using a Feed Forward Block, so that the English and French translation can be compared against one another. This computation extracts relevant information from the sentences and the translation, and will inform how it handles future translation tasks. \n"],"metadata":{"id":"YDh8JFtXN53U"}},{"cell_type":"markdown","source":["\n","### Dilated Residual Networks$^{5}$\n","\n","CNNs were originally designed for the classifying of hand-written digits and have been applied to all manner of image classification tasks. This is done, broadly speaking, by reducing the resolution of the images until very little of the original data remains. \n"," \n","However, this type of data compression could be the source of losses of accuracy - small details of an image that are critical for understanding the broader context might be compressed out of consideration. Since image classification is usually only a step in the network, with the output of such tasks passed to a downstream application, the loss of this accuity might reduce the capacity of these functions.\n"," \n","Dilated Residual Networks (DRNs) improve upon CNNs by preserving spatial resolution of the original image through the use of a sparse kernel, sampling from a distributed grid of the original image. By introducing holes in the kernel, more coverage is possible, as the kernel can be more spread out with the same memory usage. DRNs have been shown to outperform non-dilated counterparts in image classification, without increasing the model's depth or complexity.\n"," \n","<style>\n","  div {\n","    text-align: center;\n","  }\n","</style>\n"," \n","<div>\n","<img src=https://drive.google.com/uc?id=19_EJ7C6_160iKBOe-sWwn3UAuA_7qGhy width=\"750\">\n","</div>\n","Figure 5: Activation Maps, comparing the processing of images using ResNet-18 to corresponding DRNs. The class activation maps of the DRNs are much more clearly resolved than the maps extracted from the corresponding ResNet. \n"," \n","One of the computational failures of DRNs is gridding artifacts, or errors introduced by the dilated kernel. This can be seen in DRN-A-18, and occurs when the feature map has higher-frequency content than the sampling rate of the dilation. This needs to be corrected through \"degridding\" techniques, which involves adding convolution techniques at the end of the network with progressively lower dilation, and can be shown to be successful in their application in DRN-B-26.\n","\n"],"metadata":{"id":"Myw_3ztFN-lE"}},{"cell_type":"markdown","source":["### Nonlinear Principal Component Analysis Using Autoassociative Neural Networks$^{6}$\n","\n","When trying to make sense of a data set in machine learning, one objective is identifying the principal dimensions and compressing the superficial components into a smaller set of dimensions. Principal Component Analysis (PCA) has been used to reduce linearly associated dimensions and extract the dimensions that contribute the most to the data set. This results in a minimization in the minimum sum of squares difference between the data and the model. \n"," \n","Nonlinear Principal Component Analysis (NLPCA) improves on this approach by using the same dimensionality compression techniques and the same reduction of minimum sum of squared, but by also incorporating nonlinear mappings in the data. If nonlinear correlations exist within the data, NLPCA will describe those relations with a much greater degree of accuracy and fewer factors than PCA.\n"," \n","The NLPCA method involves training an artificial neural network  to generate nonlinear features - this is done using conventional feedforward, linear or sigmoidal transfer functions, and outputs are used in backpropagation. Three hidden layers are used, including an internal \"bottleneck\" layer, which has fewer dimensions than the input or output. Because of this restriction, the bottleneck layer must represent the input information in a way the subsequent layers can accurately reconstruct the input, implying that there is an accurate way to concentrate information.  \n"," \n","The NLPCA method can be used to reduce the dimensionality of data by eliminating superfluous information and removing nonlinear correlations occuring in the data. This is, in-part, possible through the bottleneck layer of the neural network used in the NLPCA method. This methodology has been shown to be more effective than PCA in describing or reducing data, and can be applied to a very similar set of problems that conventional PCA can be applied to. \n"],"metadata":{"id":"Zx5_xOUROBJQ"}},{"cell_type":"markdown","source":["\n","### Evaluating protein transfer learning with TAPE. $^{7}$\n","\n","There has been an explosion of interest and research into proteins - sequences, folding and functioning - in recent years, with rapidly growing datasets to match. With the tremendous number of sequences available to query and recent advancements in NLP, there is a need for a way to systematically evaluate semi-supervised learning on protein sequences. Tasks Assessing Protein Embedding introduces one such set of benchmarks, offering five biologically relevant supervised tasks that can be used to compare the performance of learned protein embeddings.\n"," \n","Three major areas of protein biology that the tasks help to understand include structure prediction, detection of remote homologues and protein engineering. With the benchmarking framework, different models can be tested and compared directly for the first time; this paper compares recurrent, convolutional and attention-based representation models, as well as two semi-supervised models.\n"," \n","This analysis demonstrates the improvements in performance that self-supervised pretraining offers to models and also that different architectures perform differently on different tasks. The pretrained models by in large outperformed the models without pretraining, with the pretrained transformer models showing greater success on the fluorescence task, LSTM showing greater success on the homology task and Transformer, ResNet and Alley et al. models being tied for the most success in the stability task. \n"," \n","Since the gap between labeled and unlabeled protein data continues to grow exponentially, the need for self-supervised learning to be an aspect of machine learning for proteins. Additionally, the lack of a clear model that can succeed in all tasks indicates the need for further exploration and development and the opportunity to build outside of the language modeling, and protein-specific tasks are necessary to fully develop the field.\n"],"metadata":{"id":"yYDBTYSXODrT"}},{"cell_type":"markdown","source":["### Deep generative models of genetic variation capture the effects of mutations $^{8}$\n","\n","The interactions of proteins and RNAs are complex, involving a great number of residues in the sequence; however, many approaches to understanding them focus on the individual monomers independently. DeepSequence is a probabilistic model, meaning it utilizes statistical techniques to take account of the potential randomness in a system, and it predicts the effects of mutations across protein families.\n"," \n","By considering all possible interactions between residues and how mutations might influence the entire system, the number of parameters to consider sees a combinatorial explosion. Instead of considering this full model, one can consider 'hidden' (or latent) variables underlying the observed variables. PCA and admixture analysis are types of latent-variable models, linearly connecting visible data to hidden variables. This procedure is expanded by the incorporation of flexible nonlinear transformations, which is achieved by DeepSequence. Using a Bayesian deep latent-variable model, the latent structure of sequence families is revealed.\n"," \n","Predictions using the deep latent-variable model were shown to be more accurate than either a pairwise-interaction approach or supervised methods. Additionally, the model learned accessible interpretations of the protein structures, mapping onto macrovariations, phylogeny and structural proximities of residues. One potential ramification, however, is the increased potential for overfitting. Additionally, the relevance of DeepSequence is dependent on both the quality and relevance of the evolutionary sequence data. All this being said, this approach is likely to be of increasing importance for high-throughput designs and annotation of biological sequence.\n"],"metadata":{"id":"IKT64qo3oie_"}},{"cell_type":"markdown","source":["# III. Conclusion - Personal Remarks\n","\n","During the first three-quarters of this course, I entirely believed that the material being presented - while fascinating - would not end up being important to my research. However, through the last few weeks, I have come to realize how geometric machine learning could be critical to understanding mutated protein functionality. \n"," \n","Something this project in particular let me further explore is the foundational models in machine learning - I feel much more confident in my understanding of the evolution of machine learning models - from CNNs to LSTMs to Transformers and DRNs and beyond. Before this review, I didn't understand why using geodesic distances could be an improvement, because I didn't know what they were improving upon. Because I now have a more fundamental understanding of the state of the field, I am more interested in how geometric machine learning can be used to improve upon it.\n"," \n","Thank you so much for your time, compassion and patience, Nina! I am really excited to work on this more in the future!\n"],"metadata":{"id":"0zVPC703L7Vx"}},{"cell_type":"markdown","source":["# IV. References\n","\n","1. Detlefsen, N.S., Hauberg, S. & Boomsma, W. Learning meaningful representations of protein sequences. Nat Commun 13, 1914 (2022). https://doi.org/10.1038/s41467-022-29443-w\n","\n","2. Hochreiter, S. & Schmidhuber, J. Long Short-Term Memory. Neural Comput. 9, 1735–1780 (1997). \n","http://www.bioinf.jku.at/publications/older/2604.pdf\n","\n","3. Varsamopoulos, Savvas & Bertels, Koen & Almudever, Carmen. (2018). Designing neural network based decoders for surface codes. \n","https://www.researchgate.net/publication/329362532_Designing_neural_network_based_decoders_for_surface_codes\n","\n","4. Vaswani, A. et al. Attention is all you need. In Advances in neural information processing systems 5998–6008 (2017). \n","https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n","\n","5. Yu, F., Koltun, V. & Funkhouser, T. Dilated residual networks. In Proceedings of the IEEE conference on computer vision and pattern recognition 472–480 (2017). \n","https://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_Dilated_Residual_Networks_CVPR_2017_paper.pdf\n","\n","6. Kramer, M. A. Nonlinear principal component analysis using autoassociative neural networks. AIChE J. 37, 233–243 (1991). \n","https://people.engr.tamu.edu/rgutier/web_courses/cpsc636_s10/kramer1991nonlinearPCA.pdf\n","\n","7. Rao, R. et al. Evaluating protein transfer learning with TAPE. In Advances in neural information processing systems 32, 9689–9701 (2019). \n","https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7774645/\n","\n","8. Riesselman, A.J., Ingraham, J.B. & Marks, D.S. Deep generative models of genetic variation capture the effects of mutations. Nat Methods 15, 816–822 (2018). \n","https://doi.org/10.1038/s41592-018-0138-4"],"metadata":{"id":"YqdqBeZZL7oB"}},{"cell_type":"code","source":[""],"metadata":{"id":"lhYPCijLo1_7"},"execution_count":null,"outputs":[]}]}